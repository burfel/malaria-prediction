# Discussion

## Technical part
<big>
Creating a good model is difficult due to specific characteristics of the data (eg outliers), especially in the case where few data are available.

In our case a parametric model was appropriate as we could identify linear relationships between variables and the response variable and the distribution of the residuals in our linear model (with parasitemia percentage as independent variable) showed fairly normal distributions (see chapter _Methods_). Ridge regression to accommodate for multicollinearity was not relevant since we aimed for a simple model with few independent variables; instead we used variable selection. For more elaborate Machine Learning (ML) methods, including Random Forest (RF) and Support Vector Machines (SVMs), there was not enough data available.

We wanted to avoid such models that generate highly complex, non-linear relationships between the predictors and the outcome. Also, we wanted to keep the model interpretable; more complex models quickly tend to lose interpretability and more importantly, overfit the data.

Another aspect we considered when designing the models was the type of data a user is most likely to have. 
Our model(s) still need to be properly validated on independent data. Although we could achieve significant p-value for the F-test (< 0.05) for both the simple and the complex model (see chapter _Results_), we did not achieve a high R-squared value (< 0.4) that indicates how much variation in the output variable is explained by the input variables. Most of the variation (1-R-squared) is still unaccounted for. This might be due to measurement errors, the majority is probably noise. 

Once more data has become available, it might be meaningful to explore more elaborate non-parametric predictive models that are more powerful. 

We might want to consider models where outliers do not have much influence on the model, eg tree-based classification models if we formulate our problem as a classification problem or lasso and elastic-net regularized linear models. Also SVMs for classification generally disregard a part of the training set (that may be far away from the decision boundary and outside of the data mainstream) when creating a prediction equation. However, there is always a trade-off between performance on existent data set and over-fitting, and also the loss of interpretability in case of ML methods. In any case, the complex model should be properly validated and for model selection common estimator such as Aikaike information criterion (AIC) or Bayesian information criterion (BIC) should be used.

However, this was not the purpose of this project.

## Practical relevance
The web tool in chapter _Results_ is ready to use and will be maintained and further developed and validated by the author. 
The motivation for the development of this tool was outlined in chapter _Introduction_. Dual RNA-seq used to understand host-pathogen interactions is an expensive and labour-intensive process, that is dependent on mainly two factors (sequence depth and number of samples). For the former, malaria researchers want to know the number of reads required in order to achieve a certain minimum sequencing depths for both host and parasite in order to quantify their gene expression. Here our web tool can contribute to predict the average percentage of dual RNA-seq reads that will map to the host and to the pathogen given some basic information on the sample.  

## Who might use the tool? What does the tool allow people to do?
The tool can be used by malaria researchers or other users alike who want to achieve some percentage of pathogen and/or host mapping of their sample and have parasitemia and optionally white blood cell data to their disposal. 
Moreover, the tool allows the user to get an idea of what amount of parsitemia they need to have in their sample in order to get a specific target percentage of pathogen and host mapping of their reads using the sliders on the sidepanel.
They can get the direct result from the output computed based on a logistic regression model and optionally compare it to the linear regression model shown in the plot. The tool allows zooming and saving the plot as well as showing the exact coordinates when hovering over the plot. Optionally, the user can perform different statistical tests to compare the available models, including likelihood ratio, Chi-Squared, F and Rao test.

## Limitations
Besides the technical points pointed out above, there are some limitations to the predictability performance of the model due to the specific training data set that was used.
The model was built based on one single data set in Gambian children (see chapter _Data_ and [1] for more information on the data set). It might very likely be not generalisable to other settings and ages. Also, it constists only of one type of RNA-seq data (Ribosomal RNA depleted, Globin Depleted RNA), and may not be directly equivalent to results from other preparation methods, eg PolyA.

<!--
Thre predictive performance, provided the complex model is properly validated, may compensate the loss in interpretation. 
-->

## Outlook
For more complex models, one might want to incorporate the information of the developmental stage of the disease (given by the surrogate proportion variables (SPVs) at different time points in the life cycle) as well the level of gametocytes (Gam5) representing the sexual stage of the parasite.
The observations found in chapter _Data_ might help for that.

Also, additional insight might be gained by comparing different species. We developed a logistic regression on the mouse data set; however, comparison to our models behind this web tool here, turned out to be difficult as it was not based on the same measurements and very few data was available. 

Once more data has become available, we might also want analyse with respect to different subject ID groups.
</big>
<!---
Main problems

- not enough data

- Machine Learning methods not applied since overfitting and interpretability...

- outliers, dimension of data
transformations for multiple predictors

-->

<!--
If the model is very senstive to outliers (which is not the case here), we could use the __spaial sign__ transformation (Seernels et al. 2006 INSERT IN REFERENCE LIST) which projects the predictor values onto a multidimensional sphere and thus makes all the samples the same distance from the centre of the sphere. This is mathematically done by each sample divided by its squared norm INSERT FORMULA HERE. One should note that centering and scaling of the predictor data is necessary because the denominator is intended to measure the squared distance to the centre of thre predictor's distribution. Also, this method transforms the predictors as a group, so we should not remove predictor variables after it. 
-->
