## Discussion: The model
<big>
Creating a good model is difficult due to specific characteristics of the data (eg outliers), especially in the case where few data are available.

In our case a parametric model was appropriate as we could identify linear relationships between variables and the response variable and the distribution of the residuals in our linear model (with parasitemia percentage as independent variable) showed fairly normal distributions (see chapter _Methods_). Ridge regression to accommodate for multicollinearity was not relevant since we aimed for a simple model with few independent variables; instead we used variable selection. For more elaborate Machine Learning (ML) methods, including Random Forest (RF) and Support Vector Machines (SVMs), there was not enough data available.

We wanted to avoid such models that generate highly complex, non-linear relationships between the predictors and the outcome. Also, we wanted to keep the model interpretable; more complex models quickly tend to lose interpretability and more importantly, overfit the data.

Another aspect we considered when designing the models was the type of data a user is most likely to have. 
Our model(s) still need to be properly validated on independent data. Although we could achieve significant p-value for the F-test (< 0.05) for both the simple and the complex model (see chapter _Results_), we did not achieve a high R-squared value (< 0.4) that indicates how much variation in the output variable is explained by the input variables. Most of the variation (1-R-squared) is still unaccounted for. This might be due to measurement errors, the majority is probably noise. 

Once more data has become available, it might be meaningful to explore more elaborate non-parametric predictive models that are more powerful. 

We might want to consider models where outliers do not have much influence on the model, eg tree-based classification models if we formulate our problem as a classification problem or lasso and elastic-net regularized linear models. Also SVMs for classification generally disregard a part of the training set (that may be far away from the decision boundary and outside of the data mainstream) when creating a prediction equation. However, there is always a trade-off between performance on existent data set and over-fitting, and also the loss of interpretability in case of ML methods. In any case, the complex model should be properly validated and for model selection common estimator such as Aikaike information criterion (AIC) or Bayesian information criterion (BIC) should be used.

However, this was not the purpose of this project.
</big>
